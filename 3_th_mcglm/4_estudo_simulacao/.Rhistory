models[[i]] <- fit
print(i)
}
},
{
for (i in 1:n_datasets) {
fit <-
mcglm(linear_pred = c(form),
matrix_pred = list(c(Z0)),
link = link,
variance = variance,
data = datasets[[i]])
models[[i]] <- fit
print(i)
}
}
)
dists <- vector() # vetor para armazenar as distancias
dists[1] <- 0 # distancia inicial 0
hyp_betas <- betas # vetor inicial para distribuir os efeitos
hypothesis <- list() # vetor para armazenar as hipoteses
# hipotese inicial
hypothesis[[1]] <- paste(coef(models[[1]], type = 'beta')$Parameters,
'=',
betas)
# obtenção das distâncias e hipóteses a serem testadas
for (i in 2:n_distances) {
hyp_betas[1] <- hyp_betas[1] - (betas[1]/n_distances)
hyp_betas[2:length(betas)] <- hyp_betas[2:length(betas)] + (betas[1]/n_distances)/(n_treatment-1)
hypothesis[[i]] <- paste(coef(models[[1]], type = 'beta')$Parameters,
'=',
hyp_betas)
dists[[i]] <- dist(rbind(betas, hyp_betas), method = "euclidean")
}
dists
dists <- dists/sd(dists)
dists
distribution = 'poisson'
betas = c(2.31,0,0,0)
# tratamentos
trat <- gl(n_treatment, sample_size/n_treatment)
# matriz do modelo
X <- model.matrix(~ trat)
# lista para armazenar os conjuntos de dados
datasets <- list()
switch(distribution,
"normal" = {
link <- c("identity")
variance <- c("constant")
for (i in 1:n_datasets) {
mu <- X%*%betas
y <- rnorm(sample_size, mean = mu, sd = 1)
datasets[[i]] <- data.frame(y = y,
x = trat)
}
},
"poisson" = {
link <- c("log")
variance <- c("tweedie")
for (i in 1:n_datasets) {
lambda <- exp(X%*%betas)
y <- rpois(sample_size,
lambda = lambda)
datasets[[i]] <- data.frame(y = y,
x = trat)
}
},
"binomial" = {
link <-  "logit"
variance  <-  "binomialP"
for (i in 1:n_datasets) {
p <- exp(X%*%betas)/(1 + exp(X%*%betas))
y <- rbinom(sample_size,
p = p,
size = 1)
datasets[[i]] <- data.frame(y = y,
x = trat)
}
},
"beta" = {
link <- "logit"
variance <- "binomialP"
for (i in 1:n_datasets) {
p <- exp(X%*%betas)/(1 + exp(X%*%betas))
y <- gamlss.dist::rBE(sample_size,
mu = p,
sigma = 0.2)
datasets[[i]] <- data.frame(y = y,
x = trat)
}
}
)
switch(distribution,
"binomial" = {form = y/1~x},
{form = y~x}
)
# preditor matricial
Z0 <- mc_id(datasets[[1]]) # matriz identidade para o preditor matricial
models <- list()
switch(distribution,
"binomial" = {
for (i in 1:n_datasets) {
fit <-
mcglm(linear_pred = c(form),
matrix_pred = list(c(Z0)),
link = link,
variance = variance,
Ntrial = list(10),
data = datasets[[i]])
models[[i]] <- fit
print(i)
}
},
{
for (i in 1:n_datasets) {
fit <-
mcglm(linear_pred = c(form),
matrix_pred = list(c(Z0)),
link = link,
variance = variance,
data = datasets[[i]])
models[[i]] <- fit
print(i)
}
}
)
dists <- vector() # vetor para armazenar as distancias
dists[1] <- 0 # distancia inicial 0
hyp_betas <- betas # vetor inicial para distribuir os efeitos
hypothesis <- list() # vetor para armazenar as hipoteses
# hipotese inicial
hypothesis[[1]] <- paste(coef(models[[1]], type = 'beta')$Parameters,
'=',
betas)
# obtenção das distâncias e hipóteses a serem testadas
for (i in 2:n_distances) {
hyp_betas[1] <- hyp_betas[1] - (betas[1]/n_distances)
hyp_betas[2:length(betas)] <- hyp_betas[2:length(betas)] + (betas[1]/n_distances)/(n_treatment-1)
hypothesis[[i]] <- paste(coef(models[[1]], type = 'beta')$Parameters,
'=',
hyp_betas)
dists[[i]] <- dist(rbind(betas, hyp_betas), method = "euclidean")
}
dists
dists <- dists/sd(dists)
dists
betas = c(0.05,0,0,0)
distribution = 'binomial'
# tratamentos
trat <- gl(n_treatment, sample_size/n_treatment)
# matriz do modelo
X <- model.matrix(~ trat)
# lista para armazenar os conjuntos de dados
datasets <- list()
switch(distribution,
"normal" = {
link <- c("identity")
variance <- c("constant")
for (i in 1:n_datasets) {
mu <- X%*%betas
y <- rnorm(sample_size, mean = mu, sd = 1)
datasets[[i]] <- data.frame(y = y,
x = trat)
}
},
"poisson" = {
link <- c("log")
variance <- c("tweedie")
for (i in 1:n_datasets) {
lambda <- exp(X%*%betas)
y <- rpois(sample_size,
lambda = lambda)
datasets[[i]] <- data.frame(y = y,
x = trat)
}
},
"binomial" = {
link <-  "logit"
variance  <-  "binomialP"
for (i in 1:n_datasets) {
p <- exp(X%*%betas)/(1 + exp(X%*%betas))
y <- rbinom(sample_size,
p = p,
size = 1)
datasets[[i]] <- data.frame(y = y,
x = trat)
}
},
"beta" = {
link <- "logit"
variance <- "binomialP"
for (i in 1:n_datasets) {
p <- exp(X%*%betas)/(1 + exp(X%*%betas))
y <- gamlss.dist::rBE(sample_size,
mu = p,
sigma = 0.2)
datasets[[i]] <- data.frame(y = y,
x = trat)
}
}
)
switch(distribution,
"binomial" = {form = y/1~x},
{form = y~x}
)
# preditor matricial
Z0 <- mc_id(datasets[[1]]) # matriz identidade para o preditor matricial
models <- list()
switch(distribution,
"binomial" = {
for (i in 1:n_datasets) {
fit <-
mcglm(linear_pred = c(form),
matrix_pred = list(c(Z0)),
link = link,
variance = variance,
Ntrial = list(10),
data = datasets[[i]])
models[[i]] <- fit
print(i)
}
},
{
for (i in 1:n_datasets) {
fit <-
mcglm(linear_pred = c(form),
matrix_pred = list(c(Z0)),
link = link,
variance = variance,
data = datasets[[i]])
models[[i]] <- fit
print(i)
}
}
)
models
dists <- vector() # vetor para armazenar as distancias
dists[1] <- 0 # distancia inicial 0
hyp_betas <- betas # vetor inicial para distribuir os efeitos
hypothesis <- list() # vetor para armazenar as hipoteses
# hipotese inicial
hypothesis[[1]] <- paste(coef(models[[1]], type = 'beta')$Parameters,
'=',
betas)
# obtenção das distâncias e hipóteses a serem testadas
for (i in 2:n_distances) {
hyp_betas[1] <- hyp_betas[1] - (betas[1]/n_distances)
hyp_betas[2:length(betas)] <- hyp_betas[2:length(betas)] + (betas[1]/n_distances)/(n_treatment-1)
hypothesis[[i]] <- paste(coef(models[[1]], type = 'beta')$Parameters,
'=',
hyp_betas)
dists[[i]] <- dist(rbind(betas, hyp_betas), method = "euclidean")
}
dists
dists/sd(dists)
sample_size = 25
n_datasets = 10
n_treatment = 4
initial_betas = c(5,0,0,0)
n_distances = 20
distribution = 'normal'
betas <- list() # lista para armazenar os betas para gerar datasets
betas[[1]] <- initial_betas # primeiro elemento igual aos betas iniciais
dists <- vector() # vetor para armazenar as distancias
dists[1] <- 0 # distancia inicial 0
hyp_betas <- initial_betas # vetor inicial para distribuição de efeitos
for (i in 2:n_distances) {
hyp_betas[1] <- hyp_betas[1] - (initial_betas[1]/n_distances)
hyp_betas[2:length(initial_betas)] <- hyp_betas[2:length(initial_betas)] + (initial_betas[1]/n_distances)/(n_treatment-1)
betas[[i]] <- hyp_betas
dists[[i]] <- dist(rbind(initial_betas, hyp_betas), method = "euclidean")
dists <- dists/sd(dists)
}
for (i in 2:n_distances) {
hyp_betas[1] <- hyp_betas[1] - (initial_betas[1]/n_distances)
hyp_betas[2:length(initial_betas)] <- hyp_betas[2:length(initial_betas)] + (initial_betas[1]/n_distances)/(n_treatment-1)
betas[[i]] <- hyp_betas
dists[[i]] <- dist(rbind(initial_betas, hyp_betas), method = "euclidean")
}
dists
betas <- list() # lista para armazenar os betas para gerar datasets
betas[[1]] <- initial_betas # primeiro elemento igual aos betas iniciais
dists <- vector() # vetor para armazenar as distancias
dists[1] <- 0 # distancia inicial 0
hyp_betas <- initial_betas # vetor inicial para distribuição de efeitos
for (i in 2:n_distances) {
hyp_betas[1] <- hyp_betas[1] - (initial_betas[1]/n_distances)
hyp_betas[2:length(initial_betas)] <- hyp_betas[2:length(initial_betas)] + (initial_betas[1]/n_distances)/(n_treatment-1)
betas[[i]] <- hyp_betas
dists[[i]] <- dist(rbind(initial_betas, hyp_betas), method = "euclidean")
}
dists
dists <- dists/sd(dists)
dists
# tratamentos
trat <- gl(n_treatment, sample_size/n_treatment)
# matriz do modelo
X <- model.matrix(~ trat)
# lista para armazenar os conjuntos de dados
datasets <- list()
switch(distribution,
"normal" = {
link <- c("identity")
variance <- c("constant")
for (j in 1:length(betas)) {
datasets[[j]] <- list()
length(datasets[[j]]) <- n_datasets
for (i in 1:n_datasets) {
mu <- X%*%betas[[j]]
y <- rnorm(sample_size, mean = mu, sd = 1)
datasets[[j]][[i]] <- data.frame(y = y,
x = trat)
}
}
},
"poisson" = {
link <- c("log")
variance <- c("tweedie")
for (j in 1:length(betas)) {
datasets[[j]] <- list()
length(datasets[[j]]) <- n_datasets
for (i in 1:n_datasets) {
lambda <- exp(X%*%betas[[j]])
y <- rpois(sample_size,
lambda = lambda)
datasets[[j]][[i]] <- data.frame(y = y,
x = trat)
}
}
},
"binomial" = {
link <-  "logit"
variance  <-  "binomialP"
for (j in 1:length(betas)) {
datasets[[j]] <- list()
length(datasets[[j]]) <- n_datasets
for (i in 1:n_datasets) {
p <- exp(X%*%betas[[j]])/(1 + exp(X%*%betas[[j]]))
y <- rbinom(sample_size,
p = p,
size = 1)
datasets[[j]][[i]] <- data.frame(y = y,
x = trat)
}
}
},
"beta" = {
link <- "logit"
variance <- "binomialP"
for (j in 1:length(betas)) {
datasets[[j]] <- list()
length(datasets[[j]]) <- n_datasets
for (i in 1:n_datasets) {
p <- exp(X%*%betas[[j]])/(1 + exp(X%*%betas[[j]]))
y <- gamlss.dist::rBE(sample_size,
mu = p,
sigma = 0.2)
datasets[[j]][[i]] <- data.frame(y = y,
x = trat)
}
}
}
)
switch(distribution,
"binomial" = {form = y/1~x},
{form = y~x}
)
# preditor matricial
Z0 <- mc_id(datasets[[1]][[1]]) # matriz identidade para o preditor matricial
models <- list()
switch(distribution,
"binomial" = {
for (j in 1:length(betas)) {
models[[j]] <- list()
length(models[[j]]) <- n_datasets
for (i in 1:n_datasets) {
fit <-
mcglm(linear_pred = c(form),
matrix_pred = list(c(Z0)),
link = link,
variance = variance,
Ntrial = list(10),
data = datasets[[j]][[i]])
models[[j]][[i]] <- fit
print(paste(j,i))
}
}
},
{
for (j in 1:length(betas)) {
models[[j]] <- list()
length(models[[j]]) <- n_datasets
for (i in 1:n_datasets) {
fit <-
mcglm(linear_pred = c(form),
matrix_pred = list(c(Z0)),
link = link,
variance = variance,
data = datasets[[j]][[i]])
models[[j]][[i]] <- fit
print(paste(j,i))
}
}
}
)
hypothesis <- paste(coef(models[[1]][[1]], type = 'beta')$Parameters,
'=',
initial_betas)
p_test <- matrix(nrow = length(betas),
ncol = n_datasets)
for (j in 1:length(betas)) {
for (i in 1:n_datasets) {
p_test[j,i] <-  mc_linear_hypothesis(object =  models[[j]][[i]],
hypothesis = hypothesis)$P_valor
}
}
p_test <-NA
# converte resultado para dataframe
p_test <- as.data.frame(p_test)
p_test
# acrescenta info de distancia
p_test$dist <- dists
dists
library(mcglm)
library(Matrix)
#----------------------------------------------------------------
# minhas funções
source('~/msc/3_th_mcglm/0_funcoes/functions.R')
source('~/msc/3_th_mcglm/4_estudo_simulacao/varia_hipotese.R')
source('~/msc/3_th_mcglm/4_estudo_simulacao/varia_modelo.R')
source('~/msc/3_th_mcglm/4_estudo_simulacao/analises/grafico.R')
betas = c(2.3,0,0,0)
exp(X%*%betas)
sample_size = 10
n_datasets = 10
n_treatment = 4
n_distances = 20
betas_normal = c(5,0,0,0)
betas_poisson = c(2.3,0,0,0)
betas_binomial = c(0.05,0,0,0)
sample_size = 10
n_datasets = 10
n_treatment = 4
n_distances = 20
betas_normal = c(5,0,0,0)
betas_poisson = c(2.3,0,0,0)
betas_binomial = c(0.05,0,0,0)
initial_betas_normal = c(5,0,0,0)
initial_betas_poisson = c(2.3,0,0,0)
initial_betas_binomial = c(0.05,0,0,0)
normal1 <- varia_hipotese(sample_size = sample_size,
n_datasets = n_datasets,
n_treatment = n_treatment,
betas = betas_normal,
n_distances = n_distances,
distribution = 'normal')
normal1
normal2 <- varia_modelo(sample_size = sample_size,
n_datasets = n_datasets,
n_treatment = n_treatment,
initial_betas = initial_betas_normal,
n_distances = n_distances,
distribution = 'normal')
normal1
normal2
grafico(normal1, main = 'Normal - varia hipótese')
grafico(normal2, main = 'Normal - varia modelo')
poisson1 <- varia_hipotese(sample_size = sample_size,
n_datasets = n_datasets,
n_treatment = n_treatment,
betas = betas_poisson,
n_distances = n_distances,
distribution = 'poisson')
poisson2 <- varia_modelo(sample_size = sample_size,
n_datasets = n_datasets,
n_treatment = n_treatment,
initial_betas = initial_betas_poisson,
n_distances = n_distances,
distribution = 'poisson')
grafico(poisson1, main = 'Poisson - varia hipótese')
grafico(poisson2, main = 'Poisson - varia modelo')
binomial1 <- varia_hipotese(sample_size = sample_size,
n_datasets = n_datasets,
n_treatment = n_treatment,
betas = betas_binomial,
n_distances = n_distances,
distribution = 'binomial')
binomial2 <- varia_modelo(sample_size = sample_size,
n_datasets = n_datasets,
n_treatment = n_treatment,
initial_betas = initial_betas_binomial,
n_distances = n_distances,
distribution = 'binomial')
binomial1
binomial2
sample_size = 1000
binomial1 <- varia_hipotese(sample_size = sample_size,
n_datasets = n_datasets,
n_treatment = n_treatment,
betas = betas_binomial,
n_distances = n_distances,
distribution = 'binomial')
binomial2 <- varia_modelo(sample_size = sample_size,
n_datasets = n_datasets,
n_treatment = n_treatment,
initial_betas = initial_betas_binomial,
n_distances = n_distances,
distribution = 'binomial')
binomial1
binomial2
grafico(binomial1, main = 'Binomial - varia hipótese')
grafico(binomial2, main = 'Binomial - varia modelo')
