)
# lista para armazenar os conjuntos de dados
datasets <- list()
for (i in 1:(n_datasets)) {
data_temp <- genNORTARA(n = sample_size,
cor_matrix = Omega,
paramslists = paramslists,
invcdfnames = invcdfnames)
y <- c(t(data_temp))
datasets[[i]] <- data.frame(y = y,
id = rep(1:sample_size,
each = n_rep))
}
switch(distribution,
"binomial" = {form = y/1~1},
{form = y~1}
)
form
# preditor matricial
Z0 <- mc_id(datasets[[1]]) # matriz identidade para o preditor matricial
Z1 <- mc_mixed(~0 + as.factor(id), data = datasets[[1]])
models <- list()
switch(distribution,
"poisson" = {
for (i in 1:n_datasets) {
fit <-
mcglm(linear_pred = c(form),
matrix_pred = list(c(Z0, Z1)),
link = link,
variance = variance,
data = datasets[[i]])
models[[i]] <- fit
print(i)
}
},
"binomial" = {
for (i in 1:n_datasets) {
fit <-
mcglm(linear_pred = c(form),
matrix_pred = list(c(Z0, Z1)),
link = link,
variance = variance,
Ntrial = list(1),
data = datasets[[i]])
models[[i]] <- fit
print(i)
}
}
)
dists <- vector() # vetor para armazenar as distancias
dists[1] <- 0 # distancia inicial 0
hyp_taus <- taus # vetor inicial para distribuir os efeitos
hypothesis <- list() # vetor para armazenar as hipoteses
# hipotese inicial
hypothesis[[1]] <- paste(coef(models[[1]], type = 'tau')$Parameters,
'=',
taus)
# obtenção das distâncias e hipóteses a serem testadas
for (i in 2:n_distances) {
hyp_taus <- hyp_taus - (taus/n_distances)
hypothesis[[i]] <- paste(coef(models[[1]], type = 'tau')$Parameters,
'=',
hyp_taus)
dists[[i]] <- dist(rbind(taus, hyp_taus), method = "euclidean")
}
dists
dists <- dists/sd(dists)
dists
parameters <- data.frame(Parameters = coef(models[[1]])$Parameters,
Type = coef(models[[1]])$Type)
for (i in 1:(n_datasets)) {
parameters[,i+2] <- coef(models[[i]])$Estimates
}
vcovs <- list()
for (i in 1:(n_datasets)) {
vcovs[[i]] <- vcov(models[[i]])
}
p_test <- matrix(nrow = length(hypothesis),
ncol = length(models))
for (i in 1:length(models)) {
for (j in 1:length(hypothesis)) {
p_test[j,i] <- try(mc_linear_hypothesis(object =  models[[i]],
hypothesis = hypothesis[[j]])$P_valor)
}
}
# converte resultado para dataframe
p_test <- as.data.frame(p_test)
rej <- ifelse(p_test[,1:(ncol(p_test))] < 0.05, 1, 0)
df_final <- data.frame(dist = dists,
rej = ((rowSums(rej))/ncol(rej))*100)
df_final$distribution <- paste('uni', distribution)
df_final$sample_size <- sample_size
df_final$n_datasets <- ncol(rej)
df_final
sample_size = 250
n_datasets = 1
n_rep = 5
taus = c(0.5,0.5)
n_distances = 20
n_distances = 20
distribution = 'binomial'
## Matrix linear predictor
UM <- rep(1, n_rep)
Z0 <- Diagonal(n_rep, 1)
Z1 <- UM%*%t(UM)
Omega <- mc_matrix_linear_predictor(tau = taus,
Z = list(Z0, Z1))
Omega <- as.matrix(Omega, n_rep, n_rep)
Omega
## Marginais
switch(distribution,
"poisson" = {
invcdfnames <- rep('qpois', n_rep)
paramslists <- list(
m1 = list(lambda = 10),
m2 = list(lambda = 10),
m3 = list(lambda = 10),
m4 = list(lambda = 10),
m5 = list(lambda = 10)
)
link <- "log"
variance <- "tweedie"
},
"binomial" = {
invcdfnames <- rep('qbinom', n_rep)
paramslists <- list(
m1 = list(p = 0.6, size = 1),
m2 = list(p = 0.6, size = 1),
m3 = list(p = 0.6, size = 1),
m4 = list(p = 0.6, size = 1),
m5 = list(p = 0.6, size = 1)
)
link <- "logit"
variance <- "binomialP"
}
)
# lista para armazenar os conjuntos de dados
datasets <- list()
for (i in 1:(n_datasets)) {
data_temp <- genNORTARA(n = sample_size,
cor_matrix = Omega,
paramslists = paramslists,
invcdfnames = invcdfnames)
y <- c(t(data_temp))
datasets[[i]] <- data.frame(y = y,
id = rep(1:sample_size,
each = n_rep))
}
datasets
switch(distribution,
"binomial" = {form = y/1~1},
{form = y~1}
)
# preditor matricial
Z0 <- mc_id(datasets[[1]]) # matriz identidade para o preditor matricial
Z1 <- mc_mixed(~0 + as.factor(id), data = datasets[[1]])
form
link
variance
datasets
models <- list()
switch(distribution,
"poisson" = {
for (i in 1:n_datasets) {
fit <-
mcglm(linear_pred = c(form),
matrix_pred = list(c(Z0, Z1)),
link = link,
variance = variance,
data = datasets[[i]])
models[[i]] <- fit
print(i)
}
},
"binomial" = {
for (i in 1:n_datasets) {
fit <-
mcglm(linear_pred = c(form),
matrix_pred = list(c(Z0, Z1)),
link = link,
variance = variance,
Ntrial = list(1),
data = datasets[[i]])
models[[i]] <- fit
print(i)
}
}
)
summary(fit)
113-872
1113-872
dists <- vector() # vetor para armazenar as distancias
dists[1] <- 0 # distancia inicial 0
hyp_taus <- taus # vetor inicial para distribuir os efeitos
hypothesis <- list() # vetor para armazenar as hipoteses
# hipotese inicial
hypothesis[[1]] <- paste(coef(models[[1]], type = 'tau')$Parameters,
'=',
taus)
# obtenção das distâncias e hipóteses a serem testadas
for (i in 2:n_distances) {
hyp_taus <- hyp_taus - (taus/n_distances)
hypothesis[[i]] <- paste(coef(models[[1]], type = 'tau')$Parameters,
'=',
hyp_taus)
dists[[i]] <- dist(rbind(taus, hyp_taus), method = "euclidean")
}
dists <- dists/sd(dists)
parameters <- data.frame(Parameters = coef(models[[1]])$Parameters,
Type = coef(models[[1]])$Type)
for (i in 1:(n_datasets)) {
parameters[,i+2] <- coef(models[[i]])$Estimates
}
vcovs <- list()
for (i in 1:(n_datasets)) {
vcovs[[i]] <- vcov(models[[i]])
}
p_test <- matrix(nrow = length(hypothesis),
ncol = length(models))
for (i in 1:length(models)) {
for (j in 1:length(hypothesis)) {
p_test[j,i] <- try(mc_linear_hypothesis(object =  models[[i]],
hypothesis = hypothesis[[j]])$P_valor)
}
}
p_test
# converte resultado para dataframe
p_test <- as.data.frame(p_test)
rej <- ifelse(p_test[,1:(ncol(p_test))] < 0.05, 1, 0)
df_final <- data.frame(dist = dists,
rej = ((rowSums(rej))/ncol(rej))*100)
df_final$distribution <- paste('uni', distribution)
df_final$sample_size <- sample_size
df_final$n_datasets <- ncol(rej)
df_final
rej <- ifelse(p_test[,1:(ncol(p_test))] < 0.05, 1, 0)
rej
df_final <- data.frame(dist = dists,
rej = ((rowSums(rej))/ncol(rej))*100)
rej
rowSums(rej)
mc_linear_hypothesis(object =  models[[i]],
hypothesis = hypothesis[[j]]))
mc_linear_hypothesis(object =  models[[i]],
hypothesis = hypothesis[[j]])
hypothesis[[j]]
mc_linear_hypothesis(object =  models[[i]],
hypothesis = hypothesis[[1]])
vcov(fit)
round(vcov(fit))
object
object = fit
# Vetor beta chapeu
coefs <- coef(object, type = c("beta", "tau", "power"))
coefs
# Número de parametros
n_coefs <- sum(as.vector(table(coefs$Response)))
n_coefs
# Número de respostas
n_resp <- length(as.vector(table(coefs$Response)))
n_resp
# vcov
vcov_coefs <- vcov(object)[as.vector(coefs$Parameters),
as.vector(coefs$Parameters)]
vcov_coefs
# Quebrando as strings recebidas como argumento (hipóteses)
hypothesis2 <- stringr::str_split(hypothesis[[10]],
pattern = c('='),
simplify = T)
hypothesis2
# Gerando um data frame
hypothesis3 <- as.data.frame(hypothesis2)
names(hypothesis3) <- c('parameters', 'null_hyp')
# Retirando espaços
hypothesis3$parameters <- stringr::str_replace(hypothesis3$parameters, " ",  "")
hypothesis3$null_hyp <- stringr::str_replace(hypothesis3$null_hyp, " ",  "")
hypothesis3
# Gerando a matriz L
L_user <- matrix(nrow = nrow(hypothesis3), ncol = n_coefs)
colnames(L_user) <- as.vector(coefs$Parameters)
for (i in 1:nrow(L_user)) {
L_user[i,] <- ifelse(colnames(L_user) == hypothesis3$parameters[i],
1,0)
}
for (i in 1:nrow(L_user)) {
L_user[i,] <- ifelse(colnames(L_user) == hypothesis3$null_hyp[i],
-1,L_user[i,])
}
# Substitui strings por 0 (hipóteses de igualdade)
hypothesis3$null_hyp <- ifelse(stringr::str_detect(hypothesis3$null_hyp, c('beta')) == T,0,hypothesis3$null_hyp)
hypothesis3$null_hyp <- ifelse(stringr::str_detect(hypothesis3$null_hyp, c('tau')) == T,0,hypothesis3$null_hyp)
hypothesis3$null_hyp <- ifelse(stringr::str_detect(hypothesis3$null_hyp, c('power')) == T,0,hypothesis3$null_hyp)
# Converte valores da hipótese nula para numericas
hypothesis3$null_hyp <- as.numeric(hypothesis3$null_hyp)
L_user
hypothesis3
L_user
L_user%*%coefs$Estimates
vcov_coefs
L_user%*%vcov_coefs%*%t(L_user)
(solve(L_user%*%vcov_coefs%*%t(L_user)))
W <- as.numeric((t((L_user%*%coefs$Estimates) - hypothesis3$null_hyp)) %*% (solve(L_user%*%vcov_coefs%*%t(L_user))) %*% ((L_user%*%coefs$Estimates) - hypothesis3$null_hyp))
W
gl <- nrow(L_user)
p_val <- pchisq(W, df = gl, lower.tail = FALSE)
p_val
p_val <- pchisq(1, df = gl, lower.tail = FALSE)
pchisq(1, df = gl, lower.tail = FALSE)
p_val <- pchisq(0.5, df = gl, lower.tail = FALSE)
p_val
p_val <- pchisq(0.1, df = gl, lower.tail = FALSE)
p_val
p_val <- pchisq(1, df = gl, lower.tail = FALSE)
p_val
p_val <- pchisq(100, df = gl, lower.tail = FALSE)
p_val
p_val <- pchisq(20, df = gl, lower.tail = FALSE)
p_val
p_val <- pchisq(10, df = gl, lower.tail = FALSE)
p_val
p_val <- pchisq(9, df = gl, lower.tail = FALSE)
p_val
p_val <- pchisq(8, df = gl, lower.tail = FALSE)
p_val
p_val <- pchisq(7, df = gl, lower.tail = FALSE)
p_val
p_val <- pchisq(6, df = gl, lower.tail = FALSE)
p_val
p_val <- pchisq(5, df = gl, lower.tail = FALSE)
p_val
W
L_user%*%coefs$Estimates
t((L_user%*%coefs$Estimates)
as.numeric((t((L_user%*%coefs$Estimates) - hypothesis3$null_hyp)) %*% (solve(L_user%*%vcov_coefs%*%t(L_user))) %*% ((L_user%*%coefs$Estimates) - hypothesis3$null_hyp))
L_user
coefs
coefs$Estimates
hypothesis3$null_hyp
(L_user%*%coefs$Estimates) - hypothesis3$null_hyp
(solve(L_user%*%vcov_coefs%*%t(L_user)))
L_user
vcov_coefs
vcov(fit)
(solve(L_user%*%vcov_coefs%*%t(L_user)))
as.numeric((t((L_user%*%coefs$Estimates) - hypothesis3$null_hyp)) %*% (solve(L_user%*%vcov_coefs%*%t(L_user))) %*% ((L_user%*%coefs$Estimates) - hypothesis3$null_hyp))
round(vcov(fit))
round(vcov(fit), 4)
round(vcov(fit), 3)
L_user
coefs$Estimates
hypothesis3$null_hyp
L_user%*%coefs$Estimates
models
coef(fit)
c('tau11 = 0.4810090'
'tau12 = 0.5214617')
c('tau11 = 0.4810090',
'tau12 = 0.5214617')
mc_linear_hypothesis(object =  models[[i]],
hypothesis = c('tau11 = 0.4810090',
'tau12 = 0.5214617'))
models[[i]]
i
mc_linear_hypothesis(object =  fit,
hypothesis = c('tau11 = 0.4810090',
'tau12 = 0.5214617'))
p_val <- pchisq(0, df = gl, lower.tail = FALSE)
p_val
mc_linear_hypothesis(object =  fit,
hypothesis = c('tau11 = 10.4810090',
'tau12 = 10.5214617'))
mc_linear_hypothesis(object =  fit,
hypothesis = c('tau11 = 0.5',
'tau12 = 0.5'))
mc_linear_hypothesis(object =  fit,
hypothesis = c('tau11 = 0.4',
'tau12 = 0.4'))
mc_linear_hypothesis(object =  fit,
hypothesis = c('tau11 = 0.7',
'tau12 = 0.7'))
mc_linear_hypothesis(object =  fit,
hypothesis = c('tau11 = 1',
'tau12 = 1'))
mc_linear_hypothesis(object =  fit,
hypothesis = c('tau11 = 10',
'tau12 = 10'))
mc_linear_hypothesis(object =  fit,
hypothesis = c('tau11 = 100',
'tau12 = 100'))
mc_linear_hypothesis(object =  fit,
hypothesis = c('tau11 = 1000',
'tau12 = 1000'))
mc_linear_hypothesis(object =  fit,
hypothesis = c('tau11 = 0',
'tau12 = 0'))
mc_linear_hypothesis(object =  fit,
hypothesis = c('tau11 = -10',
'tau12 = -10'))
W <- as.numeric((t((L_user%*%coefs$Estimates) - hypothesis3$null_hyp)) %*% (solve(L_user%*%vcov_coefs%*%t(L_user))) %*% ((L_user%*%coefs$Estimates) - hypothesis3$null_hyp))
W
gl <- nrow(L_user)
(W*(-1))
p_val <- pchisq((W*(-1)), df = gl, lower.tail = FALSE)
p_val
W <- as.numeric((t((L_user%*%coefs$Estimates) - hypothesis3$null_hyp)) %*% (solve(L_user%*%vcov_coefs%*%t(L_user))) %*% ((L_user%*%coefs$Estimates) - hypothesis3$null_hyp))
gl <- nrow(L_user)
p_val <- pchisq((W*(-1)), df = gl, lower.tail = FALSE)
p_val
round(p_val)
round(p_val, 3)
W
hypothesis3$null_hyp
round(vcov(fit), 3)
sample_size = 50
n_datasets = 1
n_datasets = 2
n_rep = 5
taus = c(0.5,0.5)
n_distances = 20
distribution = 'binomial'
## Matrix linear predictor
UM <- rep(1, n_rep)
Z0 <- Diagonal(n_rep, 1)
Z1 <- UM%*%t(UM)
Omega <- mc_matrix_linear_predictor(tau = taus,
Z = list(Z0, Z1))
Omega <- as.matrix(Omega, n_rep, n_rep)
paramslists <- list(
m1 = list(p = 0.6, size = 10),
m2 = list(p = 0.6, size = 10),
m3 = list(p = 0.6, size = 10),
m4 = list(p = 0.6, size = 10),
m5 = list(p = 0.6, size = 10)
)
## Marginais
switch(distribution,
"poisson" = {
invcdfnames <- rep('qpois', n_rep)
paramslists <- list(
m1 = list(lambda = 10),
m2 = list(lambda = 10),
m3 = list(lambda = 10),
m4 = list(lambda = 10),
m5 = list(lambda = 10)
)
link <- "log"
variance <- "tweedie"
},
"binomial" = {
invcdfnames <- rep('qbinom', n_rep)
paramslists <- list(
m1 = list(p = 0.6, size = 10),
m2 = list(p = 0.6, size = 10),
m3 = list(p = 0.6, size = 10),
m4 = list(p = 0.6, size = 10),
m5 = list(p = 0.6, size = 10)
)
link <- "logit"
variance <- "binomialP"
}
)
# lista para armazenar os conjuntos de dados
datasets <- list()
for (i in 1:(n_datasets)) {
data_temp <- genNORTARA(n = sample_size,
cor_matrix = Omega,
paramslists = paramslists,
invcdfnames = invcdfnames)
y <- c(t(data_temp))
datasets[[i]] <- data.frame(y = y,
id = rep(1:sample_size,
each = n_rep))
}
datasets[[i]]
switch(distribution,
"binomial" = {form = y/10~1},
{form = y~1}
)
form
# preditor matricial
Z0 <- mc_id(datasets[[1]]) # matriz identidade para o preditor matricial
Z1 <- mc_mixed(~0 + as.factor(id), data = datasets[[1]])
models <- list()
switch(distribution,
"poisson" = {
for (i in 1:n_datasets) {
fit <-
mcglm(linear_pred = c(form),
matrix_pred = list(c(Z0, Z1)),
link = link,
variance = variance,
data = datasets[[i]])
models[[i]] <- fit
print(i)
}
},
"binomial" = {
for (i in 1:n_datasets) {
fit <-
mcglm(linear_pred = c(form),
matrix_pred = list(c(Z0, Z1)),
link = link,
variance = variance,
Ntrial = list(1),
data = datasets[[i]])
models[[i]] <- fit
print(i)
}
}
)
summary(models[[1]])
summary(models[[2]])
