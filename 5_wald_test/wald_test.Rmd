---
output:
  html_document: 
    type: inverse
    # Sumário
    toc: true 
    toc_depth: 3 # Profundidade do sumário                   
    toc_float:                      
      collapsed: true # Sumário flutuante (lateral)
    
#    number_sections: true # Seções numeradas
    
    # Aparência
    theme: flatly
    # Temas possíveis:
    # default,cerulean,journal,flatly,readable,spacelab,
    # united,cosmo,lumen,paper,sandstone,simplex,yeti
    
    # Códigos R no texto
#    highlight: espresso
    # Temas possíveis:
    # default, tango, pygments, kate, monochrome, 
    # espresso, zenburn, haddock, and textmate
    #css: styles.css                
    
    # Configurações globais de imagens
    fig_width: 7  # Largura                  
    fig_height: 6 # Altura                  
    fig_caption: true # Legenda              
    fig_align: 'center' # Posição

    # Esconder o código
#    code_folding: hide 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

---

<center>
<font size="6"> 
<p align=”center”> <b> Teste Wald </b> </center>
</font>
</center>

---

<font size="4"> 
<p align=”center”> [Lineu Alberto Cavazani de Freitas](https://lineu96.github.io/st/) </center>
</font> 

---

# O que é

O teste Wald é um teste de hipótese aplicado a modelos de regressão para verificar suposições sobre os parâmetros do modelo, isto é, verifcar se o parâmetro estimado é ou não estatísticamente igual a um valor qualquer.

É um teste que avalia restrições nos parâmetros de um modelo de regressão com base na distância entre a estimativa do parâmetro e o valor postulado sob a hipótese nula, esta diferença é ainda ponderada por uma medida de precisão da estimativa do modelo. Quanto mais distante de 0 for o valor da distância ponderada, menos provável de ser verdadeira é a hipótese, ou seja, do valor postulado ser igual ao valor estimado.

Além disso, o teste utiliza distribuição assintótica Qui-quadrado ( $\chi^2$ ) para verificar a validade das hipóteses e determinar significância estatística.

---

# Hipóteses

As hipóteses de interesse em que há possibilidade de se aplicar o teste Wald são do tipo:

$$H_0: \beta = \beta^* \ vs \ H_1: \beta \neq \beta^*.$$ 

Em que $\beta$ pode representar um único ou vários parâmetros de regressão a serem testados simultaneamente e $\beta^*$ representa os valores a serem testados, isto é, sob hipótese nula.

---

Uma forma alternativa de se escrever as hipóteses é:

$$H_0: L\beta = c \ vs \ H_1: L\beta \neq c.$$ 

Em que $L$ é uma matriz que especifica quais parâmetros serão testados.
Seu número de linhas é o número de parâmetros a serem testados ($q$) e o número de colunas é o mesmo que o número de parâmetros do modelo ($p$).

$\beta$ é o vetor completo de parâmetros estimados no modelo, ou seja, é um vetor de $p$ elementos.

E $c$ é um vetor de valores a serem confrontados com as estimativas originais do modelo, tem dimensão $q$.

Sendo assim, $L$ tem dimensão $qxp$, $\beta$ tem dimensão $px1$ e o produto $L\beta$ tem dimensão $qx1$, bem como $c$.

---

## Exemplos

Para fins de ilustração, considere um modelo qualquer com preditor dado por:

$$g(\mu) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3$$

---

### Hipóteses para um parâmetro 

Podemos estar interessados em testar um único parâmetro, isto é, uma hipótese como:

$$H_0: \beta_1 = 0 \ vs \ H_1: \beta_1 \neq 0.$$ 

Ou seja, estaríamos verificando se há evidência suficiente para afirmar que o parâmetro $\beta_1$ é igual a 0.

---

Esta mesma hipótese pode ser escrita na notação genérica $L\beta = c$:

$$H_0: L\beta = c \ vs \ H_1: L\beta \neq c.$$ 

Sendo assim:

 - $L$ = $\begin{bmatrix} 0 & 1 & 0 & 0 \end{bmatrix}$, uma matriz 1x4.
 
 - $\beta$ = $\begin{bmatrix} \hat\beta_0\\  \hat\beta_1\\  \hat\beta_2\\  \hat\beta_3 \end{bmatrix}$, uma matriz 4x1.
 
 - $c$ = $\begin{bmatrix} 0 \end{bmatrix}$, uma matriz 1x1.
 
Note que as dimensões são compatíveis e o resultado do produto é o mesmo que o da notação $\beta = \beta^*$.

---

### Hipóteses para múltiplos parâmetros

Considerando o mesmo preditor, podemos estar interessados em testar mais de um parâmetro ao mesmo tempo, por exemplo:

$$H_0: 
\begin{pmatrix}
\beta_1 \\ 
\beta_2 \\ 
\beta_3
\end{pmatrix} 
= 
\begin{pmatrix}
0 \\ 
0 \\ 
0
\end{pmatrix}
\ vs \ 
H_1: 
\begin{pmatrix}
\beta_1 \\ 
\beta_2 \\ 
\beta_3
\end{pmatrix} 
\neq
\begin{pmatrix}
0 \\ 
0 \\ 
0
\end{pmatrix}.$$

Neste caso, teríamos interesse em verificar se, simultâneamente, os parâmetros $\beta_1$, $\beta_2$ e $\beta_3$ são iguais a 0.

---

Esta mesma hipótese, para múltiplos parâmetros, na notação genérica $L\beta = c$, fica da seguinte forma:

$$H_0: L\beta = c \ vs \ H_1: L\beta \neq c.$$ 

Em que:

 - $L$ = $\begin{bmatrix} 0 & 1 & 0 & 0\\ 0 & 0 & 1 & 0\\ 0 & 0 & 0 & 1\end{bmatrix}$, é uma matriz 3x4.
 
 - $\beta$ = $\begin{bmatrix} \hat\beta_0\\  \hat\beta_1\\  \hat\beta_2\\  \hat\beta_3 \end{bmatrix}$, é um vetor 4x1.
 
 - $c$ = $\begin{bmatrix} 0\\  0\\  0 \end{bmatrix}$, é um vetor 3x1.
 
Note que as dimensões são compatíveis e o resultado do produto é o mesmo que o da notação $\beta = \beta^*$.

---

## Observação

Em geral, ao realizar este tipo de teste há interesse em confrontar o valor dos parâmetros estimados com 0, isto é, não é incomum utilizar vetores nulos como $\beta^*$ ou $c$. Pois desse modo podemos testar se existe evidência para afirmar que o parâmetro estimado é estatisticamente igual a 0. E caso haja evidência de que o parâmetro seja igual a 0, significa que ele não é relevante no modelo, ou seja, não tem efeito significativo.

---

Contudo podemos realizar testes com quaisquer outros valores, por exemplo:

$$H_0: \beta_1 = 2 \ vs \ H_1: \beta_1 \neq 2.$$ 

Ou, para múltiplos parâmetros simultaneamente:

$$H_0: 
\begin{pmatrix}
\beta_1 \\ 
\beta_2 \\ 
\beta_3
\end{pmatrix} 
= 
\begin{pmatrix}
2 \\ 
5 \\ 
8
\end{pmatrix}
\ vs \ 
H_1: 
\begin{pmatrix}
\beta_1 \\ 
\beta_2 \\ 
\beta_3
\end{pmatrix} 
\neq
\begin{pmatrix}
2 \\ 
5 \\ 
8
\end{pmatrix}.$$

---

Além disso, existem outros testes para verificar tais tipos de hipótese. Os mais famosos são o teste da razão de verossimilhanças e o teste escore.

Contudo o teste Wald é famoso pela sua simplicidade pois baseia-se na distribuição assintótica Normal dos estimadores dos parâmetros do modelo e para sua execução necessitamos apenas da estimativa do parâmetro e seu erro padrão (raiz da variância), geralmente obtido pela matriz de variâncias e covariâncias dos parâmetros do modelo.

---

# Teste Wald para um único parâmetro

Seja $\beta_j$ um parâmetro qualquer de um modelo de regressão e $\hat\beta_j$ a estimativa deste parâmetro, sabemos que $\beta_j$ segue distribuição Normal com média $\hat\beta_j$ e variância dada pelo correspondente termo da diagonal da matriz de variâncias e covariâncias, isto é:

$$\hat\beta_j \sim Normal(\beta_j, Var(\hat\beta_j)).$$

Neste cenário, a hipótese a ser testada para um único parâmetro, fica da seguinte forma:

$$H_0: \beta_j = \beta_j^* \\H_1: \beta_j \neq \beta_j^*$$

A estatística de teste do tipo Wald para verificar a hipótese é dada por:

$$W = \frac{(\hat\beta_j - \beta_j^*)^2}{Var(\beta_j^*)}.$$

A estatística $W$ segue distribuição assintótica Qui-quadrado com 1 grau de liberdade ($\chi^2_1$). Outra versão comum utilizada é a raiz quadrada da estatística original, dada por:

$$\sqrt{W} = \frac{\hat\beta_j - \beta_j^*}{ep(\beta_j^*)}.$$

Neste caso, a estatística de teste segue distribuição assintótica Normal Padrão ($Normal(0,1)$).

---

# Teste Wald para múltiplos parâmetros

Sabemos que, qualquer parâmetro estimado do modelo segue distribuição Normal em que a média é dada pelo valor verdadeiro do parâmetro e a variância é dada pela variância da estimativa.

Para testar a hipótese de que diversos parâmetros são, ao mesmo tempo, iguais a um vetor de valores postulados, é mais conveniente utilizar a notação $L\beta = c$. Deste modo, as hipóteses são dadas por:

$$H_0: L\beta = c \\H_1: L\beta \neq c$$

A generalização da estatística de teste para verificar a validade desta hipótese é dada por:

$$W = (L\hat\beta - c)^T \ (L \ vcov(\hat\beta) \ L^T)^{-1} \ (L\hat\beta - c).$$

Em que $L$ é uma matriz de dimensão $qxp$, que define quais parâmetros estão sendo testados. $\beta$ é o vetor de dimensão $px1$ com todos os parâmetros de regressão do modelo. $c$ é um vetor de dimensão $qx1$ com os valores sob hipótese nula. E $vcov(\hat\beta)$ é a matriz de variâncias e covariâncias das estimativas $\beta_j$ de dimensão $pxp$. 

É simples verificar que todas as matrizes são compatíveis e, especificando corretamente a matriz $L$, é possível testar hipóteses sobre parâmetros individuais. 

Independente do número de parâmetros testados estatística de teste $W$ é um único valor que segue assintóticamente distribuição $\chi^2$. Quanto aos graus de liberdade, existem duas possibilidades: a primeira é considerar como graus de liberdade o número de parâmetros testados, isto é, o número de linhas da matriz $L$, denotado por $q$. A segunda possibilidade é utilizar a diferença entre o tamanho amostral e o número de parâmetros do modelo, ou seja, $n-p$.

**(ENCONTRAR REFERÊNCIAS SOBRE A DIFERENÇA ENTRE OS GRAUS DE LIBERDADE E ESTUDAR O IMPACTO DAS DUAS ABORDAGENS)**


---

# Análise de variância

O procedimento conhecido como Análise Variância consiste em efetuar testes sucessivos impondo restrições ao modelo originalmente ajustado em que a cada passo são incluídas ou excluídas determinadas variáveis a fim de testar a ausência de determinada variável gera perda ao modelo. Normalmente os resultados destes sucessivos testes são sumarizados numa tabela que contêm a variável, o valor de uma estatística de teste, os graus de liberdade e um p-valor referente à hipótese; o chamado quadro de análise de variância.

Cuidados devem ser tomados com este tipo de análise no que diz respeito à forma como o quadro foi elaborado, pois cada linha do quadro refere-se a uma hipótese e estas hipóteses podem ser elaboradas de formas distintas. Formas conhecidas de se elaborar o quadro são as chamadas anovas do tipo I, II e III, esta nomenclatura vem do software estatístico SAS contudo não se trata de uma definição consolidada e as implementações destes tipos distintos de análise de variância não necessariamente correspondem precisamente ao que está implementado no SAS. Recomenda-se ao usuário estar seguro de qual tipo de análise está sendo utilizada pois, caso contrário, interpretações equivocadas podem ser tomadas.

Para fins de ilustração dos testes feitos por cada tipo de análise de variância, considere um modelo qualquer com preditor dado por:

$$g(\mu) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1x_2.$$

Temos deste modo um intercepto, denotado por $\beta_0$ e três parâmetros de regressão denotados por $\beta_1$, $\beta_2$ e $\beta_3$, em que $\beta_3$ representa o efeito da interação entre as variáveis $x_1$ e $x_2$.

---

## Anova tipo I

A Análise de Variância do tipo I é também chamada de análise de variância sequencial. Neste cenário, uma análise de variância sequencial faria os seguintes testes:

1. Modelo modelo apenas com $x1$ x modelo nulo.
2. Modelo com $x1$ e $x2$ x modelo com $x_1$.
3. Modelo com $x1$, $x2$ e interação x modelo com $x_1$ e $x_2$.

Cada um destes testes seria uma linha do quadro de análise de variância, e recebe o nome de sequencial pois a cada linha é acrescentada uma variável e o modelo é confrontado com o modelo da linha anterior.

Em geral, justamente por esta sequencialidade, se torna difícil interpretar os efeitos das variáveis pela análise de variância do tipo I. Em contrapartida, as análises do tipo II e III testam hipóteses que são, geralmente de maior interesse ao usuário que a do tipo I.

---

## Anova tipo II

A análise de variância do tipo II efetua testes similares à última linha da análise de variância sequencial. Em um modelo sem interação o que é feito é, em cada linha, testar o modelo completo contra o modelo sem uma variável. Deste modo se torna melhor interpretável o efeito daquela variável sobre o modelo completo.

Na presença de interações é testado o modelo sem a variável inclusive nos parâmetros em que estiver envolvido em efeitos de interação. Considerando o preditor exemplo, a análise de variância do tipo II faria os seguintes testes:

1. Modelo com $x_1$, $x_2$ e interação x modelo sem $x1$ e interação.
2. Modelo com $x_1$, $x_2$ e interação x modelo sem $x2$ e interação.
3. Modelo com $x1$, $x2$ e interação x modelo sem a interação.

Note que nas linhas em que se busca entender o efeito de $x_1$ e $x2$ também a interação é excluída, pois retira-se do modelo todos os parâmetros que envolvem aquela variável.

---

## Anova tipo III

A análise de variância do tipo III funciona do mesmo modo que uma análise de variância do tipo II sem interações. Enquanto que a análise de variância do tipo II realiza testes comparando o modelo completo contra o modelo sem todos os parâmetros que envolvem determinada variável (sejam efeitos fixos ou interações), a análise de variância do tipo III considera o modelo completo contra o modelo sem determinada variável, seja ela efeito fixo ou de interação. Deste modo, cuidados devem ser tomados nas conclusões pois uma variável não ter efeito constatado como efeito fixo não quer dizer que não haverá efeito de interação.

Considerando o preditor exemplo, a análise de variância do tipo III faria os seguintes testes:

1. Modelo com $x_1$, $x_2$ e interação x modelo sem $x1$.
2. Modelo com $x_1$, $x_2$ e interação x modelo sem $x2$.
3. Modelo com $x1$, $x2$ e interação x modelo sem a interação.

Podemos entender que a análise de variância do tipo II prioriza efeitos fixos e testa por último as interações. Já a análise de variância do tipo III considera todos os parâmetros com mesma importância, sejam eles efeitos fixos ou de interação.

Por fim, podemos notar que as análises de variância do tipo II e III geram os mesmos resultados quando para modelos sem efeitos de interação.

---

# Análise de variância via teste Wald

Considerando o que foi apresentado, podemos notar que as análises de variância são sucessivos testes de hipótese que consideram a nulidade de determinados parâmetros. Isto geralmente é feito através de uma sequência de testes de razão de verossimilhança em que, no caso do tipo I, os termos do preditor linear são acrescentados sucessivamente ao modelo, começando pelo modelo nulo.

Para as análises do tipo II e III é fácil visualizar como gerar os quadros de análise de variância utilizando o teste Wald. Pois sempre estarão sendo comparados o modelo completo e o modelo sem determinada ou determinadas variáveis. Ou seja, tratam-se de hipóteses de nulidade dos parâmetros. Basta então, para cada linha do quadro de análise de variância, especificar corretamente uma matriz $L$ que represente corretamente a hipótese a ser testada, seja para realizar o teste sobre um único parâmetro ou para múltiplos.

Para ilustração das hipóteses que seriam testadas via teste Wald em cada linha do quadro de análise de variância nos tipos II e III, considere um modelo qualquer com preditor dado por:

$$g(\mu) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_1 x_2.$$

Temos deste modo um intercepto, denotado por $\beta_0$ e quatro parâmetros de regressão denotados por $\beta_1$, $\beta_2$ e $\beta_3$ e $\beta_4$, em que $\beta_4$ representa o efeito da interação entre as variáveis $x_1$ e $x_2$.

---

## Tipo II

No caso do tipo II, testaríamos as seguintes hipóteses:

 - Na primeira linha, referente a $x_1$, testaríamos o modelo completo contra o modelo sem todos os parâmetros que possuem $x_1$, sejam fixos ou interações, portanto:

$$H_0: 
\begin{pmatrix}
\beta_1 \\ 
\beta_4
\end{pmatrix} 
= 
\begin{pmatrix}
0 \\ 
0
\end{pmatrix}
\ vs \ 
H_1: 
\begin{pmatrix}
\beta_1 \\ 
\beta_4
\end{pmatrix} 
\neq
\begin{pmatrix}
0 \\ 
0
\end{pmatrix}.$$

 - Tal como a variável $x_1$, $x_2$ está associado a um efeito de interação, portanto ambos efeitos (fixo e interação) são testados. A segunda linha do quadro, referente a $x_2$, testaria as hipóteses:
 
$$H_0: 
\begin{pmatrix}
\beta_2 \\ 
\beta_4
\end{pmatrix} 
= 
\begin{pmatrix}
0 \\ 
0
\end{pmatrix}
\ vs \ 
H_1: 
\begin{pmatrix}
\beta_2 \\ 
\beta_4
\end{pmatrix} 
\neq
\begin{pmatrix}
0 \\ 
0
\end{pmatrix}.$$

 - A terceira linha do quadro testaria uma única hipótese, pois o parâmetro $x_3$ não está associado a nenhum outro efeito:
 
$$H_0: \beta_3 = 0 \ vs \ H_1: \beta_3 \neq 0.$$ 

- Por fim, a última linha do quadro testaria o efeito da interação no modelo, ou seja:
 
$$H_0: \beta_4 = 0 \ vs \ H_1: \beta_4 \neq 0.$$ 

---

## Tipo III

Como já mencionado, a análise de variância do tipo III não trata de forma distinta efeitos fixos de interações. Portanto, os testes em cada linha do quadro de análise de variância seriam:

 - Na primeira linha, referente a $x_1$, testaríamos o modelo completo contra o modelo sem $x_1$. Note que, diferentemente da análise do tipo II mantém-se o parâmetro de interação, isto é, nada se supõe sobre ele:
 
$$H_0: \beta_1 = 0 \ vs \ H_1: \beta_1 \neq 0.$$ 

 - Na segunda linha, referente a $x_2$, testaríamos o modelo completo contra o modelo sem $x_2$. Tal como para $x_1$, na análise do tipo III nada se supõe quanto ao parâmetro de interação, por mais que lá haja $x_2$:

$$H_0: \beta_2 = 0 \ vs \ H_1: \beta_2 \neq 0.$$ 

 - O mesmo para a terceira linha:
 
$$H_0: \beta_3 = 0 \ vs \ H_1: \beta_3 \neq 0.$$ 

- Por fim, a última linha do quadro testaria o efeito da interação no modelo, ou seja, testa o modelo completo contra o modelo sem interação:
 
$$H_0: \beta_4 = 0 \ vs \ H_1: \beta_4 \neq 0.$$ 

---

## Observação

Para obtenção das demais quantidades necessárias para construção do quadro de análise de variância basta seguir o procedimento pelo qual se faz o teste Wald. Os graus de liberdade são iguais ao número de parâmetros testados, isto é, o número de linhas da matriz $L$ e o p-valor é obtido comparando o valor da estatística de teste $W$ com a distribuição $\chi^2$.

---

No caso de variáveis categóricas, são estimados o número de categorias menos um parâmetros. Neste caso, para a análise de variância, todos os parâmetros referentes à variável categória devem ter sua nulidade verificada. 

**(AO TESTAR UMA VARIAVEL CATEGÓRICA, EU NÃO ESTOU VERIFICANDO SE EXISTE DIFERENÇA ENTRE ENTRE O NÍVEL E A CATEGORIA DE REFERENCIA?)**

---

Análise de variância multivariada via teste Wald

---

<center>
<table><tr>
<td> <img src="img/dsbd.png" alt="Drawing" style="width: 250px;"/> </td>
<td> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </td>
<td> <img src="img/ufpr.jpg" alt="Drawing" style="width: 200px;"/> </td>
<td> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </td>
</center>


<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>

